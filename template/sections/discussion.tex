%!TEX root = ../report.tex
\chapter{Discussion and limitations}
\label{cha:Discussion}
In this chapter the methods implemented, and how these methods can be changed or extended to improve speed and accuracy are explored.

\section{Discussion}
\label{sec:Discussion}
% \item[Research question 1] {\em How can spatiotemporal data be integrated into exiting keyword query methods for RDF data.}
Using traditional methods for graph traversal it is possible to implement keyword search on RDF graphs. One such method is the use of BFS to find a minimum spanning subgraph containing the query words. Using spatial vertices as a root for the subgraph, creating a minimum spanning tree, it is possible to retrieve spatial data from such a keyword search. The same method is used when searching for spatial data as with other keyword searches, with the key difference being to root the BFS in a spatial vertex.

This BFS method can be implemented with a temporal dimension instead of spatial. When changing the data type of the root from spatial to temporal, the traversal method stays the same, but the root used is matched with temporal input instead of spatial input. The result tree for a temporal search can be ranked using the same methods as used for spatial search.

Combining spatial and temporal data makes spatiotemporal search possible. These searches will be rooted in a vertex containing spatial and temporal data matching the input, as defined by ``Spatiotemporal root'' in chapter \ref{rootST}. Because the root needs to contain both the spatial and the temporal input, the subset of vertices containing this will be small. This makes spatiotemporal searches quick to execute, but the accuracy and hit rate will be low. A method that could be implemented to increase the hit rate of these searches would be to change the criteria for one of the two dimensions. The search could be rooted in either space or time, and then look for the other dimension as a special case while traversing.

\subsection{Spatial and temporal vertices as special cases}
Spatiotemporal searches rooted only in time could be accomplished by discarding all result trees that are does not contain a vertex inside the queried location. To discover vertices inside a location the ``isLocatedIn'' predicate would be followed. Using this predicate to move upwards in the hierarchy the predicate creates while looking for the queried location will determine if the discovered vertex is located inside the queried location. A maximum distance of three should be used when following this predicate, as this will traverse the hierarchy up to at least country level, and possibly up to the earth vertex. Since we are looking for a specific vertex, and only looking at the vertices above in the hierarchy this will not add more than three extra visited vertices for each vertex connected with the isLocatedIn predicate. This will not increase the time used by any significant margin compared to the regular temporal search but will increase the hit rate of spatiotemporal search.

Rooting spatiotemporal search in a spatial vertex and treating the temporal dimension as a special case can be done with three different methods. Two of the methods is accomplished by looking at the predicate, and the third checks the type of literals. When using the predicate to determine if the connected vertex is temporal, the predicate can either be checked against a predetermined list of temporal predicates, or the range of valid values can be checked. Because predicates can also be treated as vertices the range can be determined by checking if the predicate have another predicate called ``rdfs:range'' connected to it. The ``rdfs:range'' predicate will have a literal on the other end. Checking if the range is ``xsd:date'' or ``xsd:dateTime'' will determine if the predicate is temporal. The final method, checks if the type of the literal is ``xsd:date'' or ``xsd:dateTime''. Since all literals have a type as part of the vertex, this is done by reading directly from the literal. Checking the predicate would add an extra traversal to each predicate connected to a vertex since the rdfs:range is treated as any other vertex. Using a predetermined list requires more knowledge of the data set and adds some small overhead. Checking the type of the objects is the fastest since this would not require any extra traversal and carries little overhead. This would not require any extra knowledge about the data set, assuming that no extra user added temporal types are created for the graph.

\subsection{Reduction of vertices and edges}
Since the number of vertices visited is the factor most correlated to time used for a search, reducing the amount of vertices visited will also reduce the time used for a search. To reduce the number of vertices, a possibility is to reduce the predicates followed. Following predicates based on type can be used to create search methods that will only follow specific predicates. This can be accomplished using natural language processing, similar to what is done in \cite{4812421,aqualog}. A less sophisticated method would be to allow for the selection of categories to be searched, then using the selected categories to extract all predicates that are connected. Because the predicates have types and properties, running a query to find all connected predicates to a category would not add more than two extra traversals, one for type, and one for property. Such a category would contain a set of types and properties that would be used to find predicates. This would make it easy to add new predicates, without having to rework the search. The same categories can be used for natural language processing, but then the query have to be preprocessed to find the categories that should be included. A downside of removing predicates, is the possibility of missing some results, and decreasing the accuracy.

Reduction of root vertices is also a method that can be implemented to increase the speed of a search. To be able to reduce the roots while maintaining accuracy, using more sophisticated natural language processing is an option. Implementing a system for inferring structure from the keywords, like that used in \cite{Elbassuoni:2011:KSO:2063576.2063615} would make it possible to find connections where the object and predicate is related to the query. Using the taxonomy from YAGO, this is possible to implement.

\subsection{Indexing and natural language processing}
It is possible to index the vertices in the graph, so that they can be searched using full text search. If all vertices are tokenized and indexed so that all vertices containing a keyword can be retrieved, this can be combined with the roots for temporal, spatial or spatiotemporal searches. Using SPARQL it is possible to find paths between two vertices using ``property paths''. From this, the shortest paths between a root and keyword vertex can be determined, and finally the roots can be ranked. This will guarantee hits for all roots, but it could be painfully slow, depending on the input keywords. Using the keyword ``south'' as an example, this keyword has 2\,798\,973 hits in the YAGO data used for the experiments in this thesis. Combining this with the average number of temporal roots from section \ref{sec:experimentalResults}, 192, this search would have to query and rank 537\,395\,904 paths, just for one keyword. Using such an index would require more than just the shortest path.

Using an index for keywords to find shortest paths without exploring the entire graph will find the best result for a given keyword. Depending on how it is implemented, it might not find the best solution for vertices containing multiple keywords. This is because a vertex containing more than one keyword at a greater distance may score higher than multiple vertices containing one keyword each at a shorter distance. The score would depend on the number of keywords in a single vertex, and the difference in depth. If even a single vertex is found at the same depth as the multi-keyword vertex, the result tree with the fewest vertices will score better.

\section{limitations}
Some temporal vertices in YAGO use a so called ``wildcard date''. These dates contain a ``\#'' symbol for parts of the date, making it impossible to directly query such dates when selecting roots. This means that the temporal search has some possible vertices missing from the set of root vertices used when traversing the graph. This could have been remedied by creating two new temporal vertices for such dates, one start date indicating the lowest possible value a wildcard date could have, and an end date indicating the highest possible value a wildcard could have.

When searching spatiotemporal data, the wildcards have been used. This was done by adding logic comparing the wildcards found connected to spatial vertices to the date range in the search. By doing this, the spatiotemporal search should be more accurate, and should retrieve some vertices that a regular temporal search would not retrieve.

Because of the large number of vertices discovered during a search, memory would run out on traversal with high distance from root. This could be solved by writing to disk, but would be slow, and since the search already reads from disk to load vertices, this would have a significant impact on search time. When testing without any form of pruning, the computer would run out of memory. Because of this, no results are gathered from a method following all edges of each vertex. Following all edges on each vertex would also lead to highly connected category vertices being discovered, resulting in artificially high hit rates for such searches.