%!TEX root = ../report.tex
\chapter{Related work}
\label{cha:related_work}
Keyword search on RDF graphs, and methods for traversal have been researched before. This research forms the basis when extending search to include spatiotemporal data.

\section{RDF graphs}
In 1999 the World Wide Web Consortium (W3C) introduced the ``Resource Description Framework Model and Syntax Specification'' \cite{brickley1999resource}. Here the first definitions of RDF were described. This was an XML based syntax designed to provide interoperability between applications on the web, in a machine-readable format. By providing information in a machine-readable fashion, the creation of automated processes should be easier to create, and by using a common standard, the same automated processes could read any page containing RDF data.

The data model of RDF can be compared to object-oriented data. RDF consists of objects, literals, and the connection between them \cite{decker2000framework}. The objects can have literals connected to them, indicating some form of data, and the objects can be connected to each other. Connections are called predicates and form the relation between an object and literal data or form the relation between two objects. This forms a graph structure, where the objects and literals are vertices, and the predicates are edges.

Modeling RDF as a graph creates a directed graph \cite{mcbride2002jena}. In this model the predicates define a direction between the two objects. Such a model is called a triple, consisting of a ``Subject predicate object'' structure\cite{decker2000framework}. Here the subject is the start vertex, the predicate defines a direction, and the object denotes the end vertex.

\section{Keyword search on graphs}
Keyword search on RDF graphs often follows a set of common strategies, that usually involves graph traversal. One method is to find vertices containing one or more keyword, then following the edges from the vertices to explore the graph and find subgraphs where the combined vertices contain as many keywords as possible while also spreading as little as possible. BLINKS \cite{blinks} propose such a method, in combination with indexing and cost balancing for expanding clusters of accessed vertices. A similar approach is used by the authors in \cite{Elbassuoni:2011:KSO:2063576.2063615} where each vertex has an associated document containing terms from the triple. When querying the keywords are matched with these documents using an inverted index, creating lists based on the matching keywords, and a subgraph is constructed by joining matches from different lists.

Another strategy for keyword search in RDF graphs is to infer triples from the query. One such query system is used in AquaLog \cite{aqualog}. This method processes the input into a triple based representation, based on a linguistic model, and then further processes the triplets into what they call ``query triples.'' Creating structured queries through inference is also done in \cite{4812421}. Here the query is first used to find vertices containing some part of the query, then the graph is explored to find a connection between the vertices. The result is a series of subgraphs with vertices that each contain part of the query. Each of the subgraphs are in turn used to create a conjunctive query with edges mapped to predicates, and vertices to subjects or objects.

Ranking and scoring the results of a search is also needed for evaluating the different methods and algorithms. A common element for ranking the results is to look at the span of the subgraphs or trees returned from the search. The shorter distance between all vertices, the more accurate a result should be. Of the above mentioned papers, three \cite{blinks, Elbassuoni:2011:KSO:2063576.2063615, 4812421} use some form of minimum spanning tree or graph when scoring or ranking the results. In addition to the minimum spanning graph, the results can be ranked by other factors.

BLINKS add a scoring system where shared vertices are counted multiple time, once for each vertex connected to it. This is done to score trees with vertices close to the root higher than vertices further away, even if the further vertices have many shared edges. The contents of the vertices are also scored based on an IR style TF/IDF method. In paper \cite{Elbassuoni:2011:KSO:2063576.2063615} the minimum subgraphs are ranked by a probabilistic model, and a language model. The probabilistic model scores a result based on the average probability for a term to occur in a triple in the subgraph. In addition, the language model is used to score some keywords higher based on what part of the triple they are found in and patterns formed from triples. This triple scoring is done by weighting words based on the structure of the triples they are found in, so keywords that occur more often in predicates are scored higher if they are found in a predicate. The final paper, \cite{4812421}, adds popularity, and keyword matching to the minimum spanning graph. Popularity is calculated based on how many edges a vertex has, so that the more connected a vertex is, the less cost a path through that vertex has. The keyword matching score is based on keyword matches in a vertex but is also weighted based on syntactic and semantic similarity, which is in turn done by using WordNet data.

\section{Spatial search on RDF graphs}
Spatial data is stored as literals connected to an entity, using predicates describing latitude or longitude. Any place vertex must have both latitude, longitude literals. Additionally, in YAGO places can use the ``isLocatedIn'' predicate\cite{hoffart2013yago2}, to establish a connection to a place with latitude and longitude. In such a case, the connected vertex can have more detailed coordinates, but it is not a requirement. This predicate also creates a hierarchy for places in the graph, as seen in figure \ref{fig:spatiotemporalTrondheim}.

Keyword searching and ranking spatial RDF graphs is quite similar to regular RDF keyword searching. Paper \cite{Shi:2016:TRS:2882903.2882941} outlines methods that incorporates spatial data into the search. These methods is similar to some of those previously mentioned here \cite{4812421, Elbassuoni:2011:KSO:2063576.2063615}. The most substantial difference is the use of R-trees to index the spatial dimension of the graph. This is done so that a subgraph can be rooted both at a real point in the world, and vertices in the graph close to the real-world point. The root is used as a starting point when traversing the graph, and like the previous methods, the goal is to find a minimum subgraph. Subgraphs are ranked based on how close the root vertex is to the selected point, the size of the tree, and how well the result tree fits the query words.

\section{Temporal search on RDF graphs}
Using the syntax specification for RDF \cite{beckett2004rdf} it is possible to declare dates as literals. Using such literals, dates and times can be connected to any vertex using a user defined predicate. A user defined predicate is any predicate created for a graph that is not part of any standard. This makes it easy to add time and date data to any graph, but some problems arise \cite{tappolet2009applied}. When adding time with user defined predicates, semantics can be lost. A predicate such as ``borneOnDate'' denotes a start date for a human but cannot be used as a start date for other concepts. It is possible to remedy this by attaching a concept such as ``startDate'' to the predicate, but this has the drawback of complicating the structure. Adding time as literals also means that the specific time is only connected to one vertex. This is a problem if a subgraph is temporal. It is a possibility to add predicates from all vertices in the subgraph to the date, but this has the drawback of creating many extra predicates.

Using literals for temporal data can be called ``time labeling''. Another method for adding time to RDF graphs is using snapshots, called ``versioning''. This method maintains the state of the graph at a given time. Such a model will create multiple versions of the graph to be able to model time. A versioned graph will be more difficult to traverse and query than one using literals \cite{gutierrez2006introducing}. 

Temporal data comes in two different forms, time points, and time intervals. Time points is modeled using a single literal. Combining two literal time points, ``[\emph{a}, \emph{b}]'' makes it possible to create a time interval, where ``\emph{a} $\leq$ \emph{b}''. Here the vertices \emph{a} and \emph{b} is usually defined by the xsd datatype \emph{date} or \emph{dateTime} \cite{tappolet2009applied}.

Using query languages such as SPARQL it is possible to query time labels. In temporal queries, time labels can be queried directly, and filtered for use in a time interval query. 

\glsresetall